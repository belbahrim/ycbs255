{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation\n",
    "Model selection is one of the important subjects in statistical modeling. We have the possibility of including as many as features, but all of them would not improve the model accuracy. It is important to know which features are improving the model. There are two different approaches: \n",
    "\n",
    "- Information theoretic approach such as AIC, BIC, Mallow's Cp.\n",
    "- Predition accuracy approach: Leave-one-out, k-fold crossvalidation.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load file\n",
    "Commonly two libraries are used to load a csv files.\n",
    "- numpy function `np.loadtext` and `np.genfromtext ` \n",
    "- pandas function `pd.read_csv`\n",
    "\n",
    "Here we prefer using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path='data/'\n",
    "filename = path+'Auto.csv'\n",
    "auto = pd.read_csv(filename, na_values=['?'], na_filter=True)\n",
    "auto = auto.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(auto['horsepower'], auto['mpg'], 'r+', mfc='none');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The seaborn package bring better styling and more plot function. The seaborn package enriches matplotlib. Let's try the regplot fucntion of seaborn for instance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns           \n",
    "#sets up styles and gives us more plotting options\n",
    "sns.regplot(x=\"horsepower\", y=\"mpg\", data=auto, ci = False,\n",
    "    scatter_kws={\"color\":\"r\", \"alpha\":0.3, \"s\":100},\n",
    "    line_kws={\"color\":\"b\", \"alpha\":0.75, \"lw\":4}, marker=\"o\", order=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quadratic model\n",
    "It appears that a quadratic model makes sense. Let's check if this guess has support from data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "model = smf.ols(formula='mpg ~ horsepower', data = auto)\n",
    "\n",
    "lr1 = model.fit()\n",
    "lr1.summary2()\n",
    "lr1.aic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols(formula='mpg ~ horsepower +\\\n",
    "                np.power(horsepower,2)', data = auto)\n",
    "lr2 = model.fit()\n",
    "lr2.aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols(formula='mpg ~ horsepower +\\\n",
    "np.power(horsepower,2)+ np.power(horsepower,3)', data = auto)\n",
    "lr3 = model.fit()\n",
    "lr3.aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols(formula='mpg ~ horsepower +\\\n",
    "np.power(horsepower,2)+ np.power(horsepower,3)+\\\n",
    "np.power(horsepower,4)', data = auto)\n",
    "lr4 = model.fit()\n",
    "lr4.aic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leave-one-out\n",
    "One of the most common validation method is leave-one-out, or n-fold crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you feed sklearn algorithms a numpy array. In many cases sklearn accepts pandas dataframes too, but it is highly recommended to feed numpy arrays into sklearn functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = auto[['horsepower']].values\n",
    "y = auto['mpg'].values\n",
    "\n",
    "rss = np.zeros(auto.shape[0])\n",
    "i = 0\n",
    "for train_i, test_i in loo.split(auto):\n",
    "    lr = LinearRegression() \n",
    "    lr = lr.fit(X[train_i], y[train_i])\n",
    "    rss[i]=(lr.predict(X[test_i]) - y[test_i])**2\n",
    "    i= i + 1\n",
    "# mse is the squared error for each sample in the test set.\n",
    "np.sum(rss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = auto[['horsepower', 'displacement']].values\n",
    "rss = np.zeros(auto.shape[0])\n",
    "i = 0\n",
    "for train_i, test_i in loo.split(auto):\n",
    "    lr = LinearRegression() \n",
    "    lr = lr.fit(X[train_i], y[train_i])\n",
    "    rss[i]=(lr.predict(X[test_i]) - y[test_i])**2\n",
    "# you may write i = i+1 as follows\n",
    "    i += 1\n",
    "np.sum(rss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "X = auto[['horsepower', 'displacement']].values\n",
    "k = 5\n",
    "rss = np.zeros(k)\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "i = 0\n",
    "for train_i, test_i in kf.split(auto):\n",
    "    lr = LinearRegression() \n",
    "    lr = lr.fit(X[train_i], y[train_i])\n",
    "    rss[i]=np.sum((lr.predict(X[test_i]) - y[test_i])**2)\n",
    "    i+=1\n",
    "rss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(rss)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
